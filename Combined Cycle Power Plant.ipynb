{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9cdc429",
   "metadata": {},
   "source": [
    "# Data Set Information \n",
    " **From the website provided:** <br> <br> The dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. Features consist of hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly electrical energy output (EP) of the plant. <br>\n",
    " \n",
    "A combined cycle power plant (CCPP) is composed of gas turbines (GT), steam turbines (ST) and heat recovery steam generators. In a CCPP, the electricity is generated by gas and steam turbines, which are combined in one cycle, and is transferred from one turbine to another. While the Vacuum is colected from and has effect on the Steam Turbine, the other three of the ambient variables effect the GT performance. <br>\n",
    "\n",
    "For comparability with our baseline studies, and to allow 5x2 fold statistical tests be carried out, we provide the data shuffled five times. For each shuffling 2-fold CV is carried out and the resulting 10 measurements are used for statistical testing.\n",
    "We provide the data both in .ods and in .xlsx formats.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f06f410",
   "metadata": {},
   "source": [
    "# Approach taken\n",
    "\n",
    "The last part of the information was found irrelevant, thus, although the data was distributed through five different sheets, it was all joined in one single sheet (since the row entries were shuffled, it was found to be no problem to join all the entries/registers together). The goal with that is to be able to handle the dataset more easily. \n",
    "\n",
    "In this project, it will be studied how the hourly average ambient variables T, AP, RH and V correlate with the EP of the power plant. The dataset will thus be divided in training and test sets. Different regression algorithms will be tried out in the training datasets and trained algorithms will be tested in the test dataset using accuracy as the metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120d75e3",
   "metadata": {},
   "source": [
    "# Dataset import and feature correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54514dad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "441de97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdefff28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      AT      V       AP     RH      PE\n",
      "0  14.96  41.76  1024.07  73.17  463.26\n",
      "1  25.18  62.96  1020.04  59.08  444.37\n",
      "2   5.11  39.40  1012.16  92.14  488.56\n",
      "3  20.86  57.32  1010.24  76.64  446.48\n",
      "4  10.82  37.50  1009.23  96.62  473.90\n",
      "\n",
      "Dataframe shape (rows, columns):  (47840, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print('\\nDataframe shape (rows, columns): ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b40b425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          AT         V        AP        RH        PE\n",
      "AT  1.000000  0.844107  0.507549  0.542535  0.948128\n",
      "V   0.844107  1.000000  0.413502  0.312187  0.869780\n",
      "AP  0.507549  0.413502  1.000000  0.099574  0.518429\n",
      "RH  0.542535  0.312187  0.099574  1.000000  0.389794\n",
      "PE  0.948128  0.869780  0.518429  0.389794  1.000000\n"
     ]
    }
   ],
   "source": [
    "corrMatrix=df.corr().abs()\n",
    "print(corrMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f771d9b",
   "metadata": {},
   "source": [
    "From the correlation matrix it is seen that the variable most correlated to the electrical output is the AT closely followed by V. Therefore, we can regard both RH and PE as less important to determine the value of PE, shifting the focus to AT and V. \n",
    "\n",
    "Moreover it is also seen that V is very correlated to AT. We could say as a rough estimate that training a regression on AT values only to determine PE could be enough to predict PE well enough, since V is very correlated to AT and AT to PE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555298d7",
   "metadata": {},
   "source": [
    "# Creating different arrays for different feature combinations\n",
    "\n",
    "Here the data will be separated into 5 numpy arrays containing the values of our variables of interest (AT, V, AT+V, AT+V+RH+PE and PE). AT will correspond to xt, V to xv, AT+V to xtv, AT+V+AP+RH (ALL) to x and PE to y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "043382c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt=df[['AT']].to_numpy()\n",
    "xv=df[['V']].to_numpy()\n",
    "xtv=df[['AT','V']].to_numpy()\n",
    "x=df[['AT','V','AP','RH']].to_numpy()\n",
    "\n",
    "y=df['PE'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1766838",
   "metadata": {},
   "source": [
    "Then, 4 different training and testing sets are created, one for AT/PE (xt/y), for V/PE (xv/y), AT+V/PE (xtv/y) and one using all features and PE (x/y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f57460c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_train, xt_test, yt_train, yt_test = train_test_split(xt, y, random_state=42) #0.75/0.25 (test/train) by default\n",
    "xv_train, xv_test, yv_train, yv_test = train_test_split(xv, y, random_state=43)\n",
    "xtv_train, xtv_test, ytv_train, ytv_test = train_test_split(xtv, y, random_state=44)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83fbbe",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f3ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrt = LinearRegression().fit(xt_train, yt_train)\n",
    "lrv = LinearRegression().fit(xv_train, yv_train)\n",
    "lrtv= LinearRegression().fit(xtv_train, ytv_train)\n",
    "lr= LinearRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fed9908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score (AT/PE): 0.90\n",
      "Test set score (AT/PE): 0.90\n",
      "Training set score (V/PE): 0.76\n",
      "Test set score (V/PE): 0.75\n",
      "Training set score (AT+V/PE): 0.92\n",
      "Test set score (AT+V/PE): 0.92\n",
      "Training set score (ALL/PE): 0.93\n",
      "Test set score (ALL/PE): 0.93\n"
     ]
    }
   ],
   "source": [
    "#print(\"Linear regression coefficient (AT/PE): {}\".format(lrt.coef_))\n",
    "#print(\"Linear regression intercept (AT/PE): {}\".format(lrt.intercept_))\n",
    "print(\"Training set score (AT/PE): {:.2f}\".format(lrt.score(xt_train, yt_train)))\n",
    "print(\"Test set score (AT/PE): {:.2f}\".format(lrt.score(xt_test, yt_test)))\n",
    "#print(\"Linear regression coefficient (V/PE): {}\".format(lrv.coef_))\n",
    "#print(\"Linear regression intercept (V/PE): {}\".format(lrv.intercept_))\n",
    "print(\"Training set score (V/PE): {:.2f}\".format(lrv.score(xv_train, yv_train)))\n",
    "print(\"Test set score (V/PE): {:.2f}\".format(lrv.score(xv_test, yv_test)))\n",
    "#print(\"Linear regression coefficient (AT+V/PE): {}\".format(lrtv.coef_))\n",
    "#print(\"Linear regression intercept (AT+V/PE): {}\".format(lrtv.intercept_))\n",
    "print(\"Training set score (AT+V/PE): {:.2f}\".format(lrtv.score(xtv_train, ytv_train)))\n",
    "print(\"Test set score (AT+V/PE): {:.2f}\".format(lrtv.score(xtv_test, ytv_test)))\n",
    "#print(\"Linear regression coefficient (ALL/PE): {}\".format(lr.coef_))\n",
    "#print(\"Linear regression intercept (ALL/PE): {}\".format(lr.intercept_))\n",
    "print(\"Training set score (ALL/PE): {:.2f}\".format(lr.score(x_train, y_train)))\n",
    "print(\"Test set score (ALL/PE): {:.2f}\".format(lr.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cf5631",
   "metadata": {},
   "source": [
    "Reasonable performance for AT, but the same cannot be said for V. Using the linear regression using both features at the same time improves the result but the best result is obtained when all four features are used to train the algorithm. \n",
    "\n",
    "A few other tests will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3783f29",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5210448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = Ridge(alpha=0).fit(xt_train, yt_train) #alpha=1 by default\n",
    "rv = Ridge(alpha=0).fit(xv_train, yv_train)\n",
    "rtv = Ridge(alpha=0).fit(xtv_train, ytv_train)\n",
    "r = Ridge(alpha=0).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6de336b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score (AT/PE): 0.90\n",
      "Test set score (AT/PE): 0.90\n",
      "Training set score (V/PE): 0.76\n",
      "Test set score (V/PE): 0.75\n",
      "Training set score (AT+V/PE): 0.92\n",
      "Test set score (AT+V/PE): 0.92\n",
      "Training set score (ALL/PE): 0.93\n",
      "Test set score (ALL/PE): 0.93\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score (AT/PE): {:.2f}\".format(rt.score(xt_train, yt_train)))\n",
    "print(\"Test set score (AT/PE): {:.2f}\".format(rt.score(xt_test, yt_test)))\n",
    "print(\"Training set score (V/PE): {:.2f}\".format(rv.score(xv_train, yv_train)))\n",
    "print(\"Test set score (V/PE): {:.2f}\".format(rv.score(xv_test, yv_test)))\n",
    "print(\"Training set score (AT+V/PE): {:.2f}\".format(rtv.score(xtv_train, ytv_train)))\n",
    "print(\"Test set score (AT+V/PE): {:.2f}\".format(rtv.score(xtv_test, ytv_test)))\n",
    "print(\"Training set score (ALL/PE): {:.2f}\".format(r.score(x_train, y_train)))\n",
    "print(\"Test set score (ALL/PE): {:.2f}\".format(r.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff75ae8d",
   "metadata": {},
   "source": [
    "Regularization doesn't make any difference here since the amount of data provided to the model is sufficiently high (different alphas were tested showing no effect). For the same reason (having more than enough data), both ridge and linear regression have the same performance. This also adds that, given a high amount of data, it becomes harder for a linear model to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bf155c",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "648079c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = Lasso().fit(xt_train, yt_train)\n",
    "lv = Lasso().fit(xv_train, yv_train)\n",
    "ltv = Lasso().fit(xtv_train, ytv_train)\n",
    "l = Lasso().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1adff37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score (AT/PE): 0.90\n",
      "Test set score (AT/PE): 0.90\n",
      "Number of features used (AT/PE): 1\n",
      "\n",
      "Training set score (V/PE): 0.76\n",
      "Test set score (V/PE): 0.75\n",
      "Number of features used (V/PE): 1\n",
      "\n",
      "Training set score (AT+V/PE): 0.92\n",
      "Test set score (AT+V/PE): 0.92\n",
      "Number of features used (AT+V/PE): 2\n",
      "\n",
      "Training set score (ALL/PE): 0.93\n",
      "Test set score (ALL/PE): 0.93\n",
      "Number of features used (ALL/PE): 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score (AT/PE): {:.2f}\".format(lt.score(xt_train, yt_train)))\n",
    "print(\"Test set score (AT/PE): {:.2f}\".format(lt.score(xt_test, yt_test)))\n",
    "print(\"Number of features used (AT/PE): {}\".format(np.sum(lt.coef_ != 0)))\n",
    "print(\"\\nTraining set score (V/PE): {:.2f}\".format(lv.score(xv_train, yv_train)))\n",
    "print(\"Test set score (V/PE): {:.2f}\".format(lv.score(xv_test, yv_test)))\n",
    "print(\"Number of features used (V/PE): {}\".format(np.sum(lv.coef_ != 0)))\n",
    "print(\"\\nTraining set score (AT+V/PE): {:.2f}\".format(ltv.score(xtv_train, ytv_train)))\n",
    "print(\"Test set score (AT+V/PE): {:.2f}\".format(ltv.score(xtv_test, ytv_test)))\n",
    "print(\"Number of features used (AT+V/PE): {}\".format(np.sum(ltv.coef_ != 0)))\n",
    "print(\"\\nTraining set score (ALL/PE): {:.2f}\".format(l.score(x_train, y_train)))\n",
    "print(\"Test set score (ALL/PE): {:.2f}\".format(l.score(x_test, y_test)))\n",
    "print(\"Number of features used (ALL/PE): {}\".format(np.sum(l.coef_ != 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4189b6a",
   "metadata": {},
   "source": [
    "Lasso gives the same results therefore reafirming the last affirmation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67ae327",
   "metadata": {},
   "source": [
    "# K-neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71bb9c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set R^2 (AT/PE): 0.873\n",
      "Test set R^2 (V/PE): 0.847\n",
      "Test set R^2 (AT+V/PE): 0.999\n",
      "Test set R^2 (ALL/PE): 1.000\n"
     ]
    }
   ],
   "source": [
    "reg=KNeighborsRegressor(n_neighbors=1)\n",
    "\n",
    "reg.fit(xt_train, yt_train)\n",
    "print(\"Test set R^2 (AT/PE): {:.3f}\".format(reg.score(xt_test, yt_test)))\n",
    "reg.fit(xv_train, yv_train)\n",
    "print(\"Test set R^2 (V/PE): {:.3f}\".format(reg.score(xv_test, yv_test)))\n",
    "reg.fit(xtv_train, ytv_train)\n",
    "print(\"Test set R^2 (AT+V/PE): {:.3f}\".format(reg.score(xtv_test, ytv_test)))\n",
    "reg.fit(x_train, y_train)\n",
    "print(\"Test set R^2 (ALL/PE): {:.3f}\".format(reg.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6105cddb",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "<u> For n_neighbors=1: <br>\n",
    "    \n",
    "Test set R^2 (AT/PE): 0.873 <br>\n",
    "Test set R^2 (V/PE): 0.847 <br>\n",
    "Test set R^2 (AT+V/PE): 0.999 <br>\n",
    "Test set R^2 (ALL/PE): 1.000 <br> <br>\n",
    "\n",
    "<u> For n_neighbors=2: <br>\n",
    "    \n",
    "Test set R^2 (AT/PE): 0.900 <br> \n",
    "Test set R^2 (V/PE): 0.887 <br>\n",
    "Test set R^2 (AT+V/PE): 0.999 <br>\n",
    "Test set R^2 (ALL/PE): 0.999 <br> <br>\n",
    "\n",
    "<u>For n_neighbors=3: <br>\n",
    "    \n",
    "Test set R^2 (AT/PE): 0.912 <br>\n",
    "Test set R^2 (V/PE): 0.897 <br>\n",
    "Test set R^2 (AT+V/PE): 0.996 <br>\n",
    "Test set R^2 (ALL/PE): 0.997 <br> <br>\n",
    "\n",
    "<u>For n_neighbors=4: <br>\n",
    "    \n",
    "Test set R^2 (AT/PE): 0.917 <br>\n",
    "Test set R^2 (V/PE): 0.901 <br> \n",
    "Test set R^2 (AT+V/PE): 0.991 <br>\n",
    "Test set R^2 (ALL/PE): 0.993 <br> <br>\n",
    "\n",
    "<u>For n_neighbors=5: <br>\n",
    "    \n",
    "Test set R^2 (AT/PE): 0.920 <br>\n",
    "Test set R^2 (V/PE): 0.904 <br>\n",
    "Test set R^2 (AT+V/PE): 0.984 <br>\n",
    "Test set R^2 (ALL/PE): 0.988 <br> <br>\n",
    "\n",
    "<u>For n_neighbors=6: <br>\n",
    "    \n",
    "Test set R^2 (AT/PE): 0.92 <br>\n",
    "Test set R^2 (V/PE): 0.90 <br>\n",
    "Test set R^2 (AT+V/PE): 0.98 <br>\n",
    "Test set R^2 (ALL/PE): 0.98 <br> <br>\n",
    "\n",
    "<u>For n_neighbors=7: <br>\n",
    "    \n",
    "Test set R^2 (AT/PE): 0.92 <br>\n",
    "Test set R^2 (V/PE): 0.91 <br>\n",
    "Test set R^2 (AT+V/PE): 0.97 <br>\n",
    "Test set R^2 (ALL/PE): 0.98 <br> <br>\n",
    "\n",
    "<u>For n_neighbors=8: <br>\n",
    "    \n",
    "Test set R^2 (AT/PE): 0.92 <br>\n",
    "Test set R^2 (V/PE): 0.91 <br>\n",
    "Test set R^2 (AT+V/PE): 0.97 <br>\n",
    "Test set R^2 (ALL/PE): 0.98 <br> <br>\n",
    "\n",
    "<u>For n_neighbors=9: <br>\n",
    "    \n",
    "Test set R^2 (AT/PE): 0.92 <br>\n",
    "Test set R^2 (V/PE): 0.91 <br>\n",
    "Test set R^2 (AT+V/PE): 0.97 <br>\n",
    "Test set R^2 (ALL/PE): 0.98 <br> <br>\n",
    "\n",
    "<u>For n_neighbors=10: <br>\n",
    "    \n",
    "Test set R^2 (AT/PE): 0.92 <br>\n",
    "Test set R^2 (V/PE): 0.91 <br>\n",
    "Test set R^2 (AT+V/PE): 0.96 <br>\n",
    "Test set R^2 (ALL/PE): 0.97 <br> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260aae97",
   "metadata": {},
   "source": [
    "We now see that a perfect prediction is obtained when using 1 neighbour for ALL, although AT+V performs almost perfectly as well. However, the R^2 for these feature combinations (AT+V and ALL) is reduced when the number of neighbours used to make the regression is increased. On the otherside, when the features AT and V are used individually to predict PE, the higher the number of neighours used, the higher the R^2 score (and thus the predicting accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e68cc7e",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b7c7f",
   "metadata": {},
   "source": [
    "In order to make a decision tree regression work, we first need to group the values for PE in different bins, as it is followed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a1fa46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=KBinsDiscretizer(n_bins=2,encode='ordinal',strategy='uniform') #uniform: bins have the same width\n",
    "\n",
    "yt_train=yt_train.reshape(-1, 1)\n",
    "yt_test=yt_test.reshape(-1, 1)\n",
    "yv_train=yv_train.reshape(-1, 1)\n",
    "yv_test=yv_test.reshape(-1, 1)\n",
    "ytv_train=ytv_train.reshape(-1, 1)\n",
    "ytv_test=ytv_test.reshape(-1, 1)\n",
    "y_train=y_train.reshape(-1, 1)\n",
    "y_test=y_test.reshape(-1, 1)\n",
    "\n",
    "yt_train = bins.fit_transform(yt_train)\n",
    "yt_test = bins.fit_transform(yt_test)\n",
    "yv_train = bins.fit_transform(yv_train)\n",
    "yv_test = bins.fit_transform(yv_test)\n",
    "ytv_train = bins.fit_transform(ytv_train)\n",
    "ytv_test = bins.fit_transform(ytv_test)\n",
    "y_train = bins.fit_transform(y_train)\n",
    "y_test = bins.fit_transform(y_test)\n",
    "\n",
    "yt_train=yt_train.reshape(1, -1)[0]\n",
    "yt_test=yt_test.reshape(1, -1)[0]\n",
    "yv_train=yv_train.reshape(1, -1)[0]\n",
    "yv_test=yv_test.reshape(1, -1)[0]\n",
    "ytv_train=ytv_train.reshape(1, -1)[0]\n",
    "ytv_test=ytv_test.reshape(1, -1)[0]\n",
    "y_train=y_train.reshape(1, -1)[0]\n",
    "y_test=y_test.reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce5c39e",
   "metadata": {},
   "source": [
    "Now the decision tree regression will be applied to the different feature combination and the target array that now instead of being a continuous value is a discrete (binned) one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dacdfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set (AT/PE): 0.957\n",
      "Accuracy on test set (AT/PE): 0.954\n",
      "Accuracy on training set (V/PE): 0.960\n",
      "Accuracy on test set (V/PE): 0.958\n",
      "Accuracy on training set (AT+V/PE): 0.999\n",
      "Accuracy on test set (AT+V/PE): 0.992\n",
      "Accuracy on training set (ALL/PE): 1.000\n",
      "Accuracy on test set (ALL/PE): 0.991\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(random_state=50,max_depth=1000)\n",
    "\n",
    "tree.fit(xt_train, yt_train)\n",
    "print(\"Accuracy on training set (AT/PE): {:.3f}\".format(tree.score(xt_train, yt_train)))\n",
    "print(\"Accuracy on test set (AT/PE): {:.3f}\".format(tree.score(xt_test, yt_test)))\n",
    "tree.fit(xv_train, yv_train)\n",
    "print(\"Accuracy on training set (V/PE): {:.3f}\".format(tree.score(xv_train, yv_train)))\n",
    "print(\"Accuracy on test set (V/PE): {:.3f}\".format(tree.score(xv_test, yv_test)))\n",
    "tree.fit(xtv_train, ytv_train)\n",
    "print(\"Accuracy on training set (AT+V/PE): {:.3f}\".format(tree.score(xtv_train, ytv_train)))\n",
    "print(\"Accuracy on test set (AT+V/PE): {:.3f}\".format(tree.score(xtv_test, ytv_test)))\n",
    "tree.fit(x_train, y_train)\n",
    "print(\"Accuracy on training set (ALL/PE): {:.3f}\".format(tree.score(x_train, y_train)))\n",
    "print(\"Accuracy on test set (ALL/PE): {:.3f}\".format(tree.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69f796b",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "<u>For n_bins=2: <br>\n",
    "\n",
    "Accuracy on training set (AT/PE): 0.957 <br>\n",
    "Accuracy on test set (AT/PE): 0.954 <br>\n",
    "Accuracy on training set (V/PE): 0.960 <br>\n",
    "Accuracy on test set (V/PE): 0.958 <br>\n",
    "Accuracy on training set (AT+V/PE): 0.999 <br>\n",
    "Accuracy on test set (AT+V/PE): 0.992 <br>\n",
    "Accuracy on training set (ALL/PE): 1.000 <br>\n",
    "Accuracy on test set (ALL/PE): 0.991 <br> <br>\n",
    "\n",
    "<u>For n_bins=3: <br>\n",
    "    \n",
    "Accuracy on training set (AT/PE): 0.888 <br>\n",
    "Accuracy on test set (AT/PE): 0.869 <br>\n",
    "Accuracy on training set (V/PE): 0.854 <br>\n",
    "Accuracy on test set (V/PE): 0.851 <br>\n",
    "Accuracy on training set (AT+V/PE): 0.999 <br>\n",
    "Accuracy on test set (AT+V/PE): 0.971 <br>\n",
    "Accuracy on training set (ALL/PE): 1.000 <br>\n",
    "Accuracy on test set (ALL/PE): 0.975 <br>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2d5cc7",
   "metadata": {},
   "source": [
    "Using a simple decision tree the results obtained are very satisfactory for all the different feature combinations, having the best results when only 2 bins are used in the decision tree (all the value of PE are diveded into 2 bins). This method gives by far the best results when AT and V are used individually to predict PE. However, the k-nearest neighbours algorithm performs yet better so far for both AT+V and ALL from 1 to 3 neighbours. Another interesting observation is that this is the first algorithm getting a better accuracy in the test set for AT+V than for ALL.\n",
    "\n",
    "Since the best result obtained for the binned discretization of the PE array was for n_bins=2, this value will further be used for a random forest algorithm (since random forests predictive results are based in those of individual decision trees)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10861c37",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8abd36a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set (AT/PE): 0.956\n",
      "Accuracy on test set (AT/PE): 0.953\n",
      "Accuracy on training set (V/PE): 0.960\n",
      "Accuracy on test set (V/PE): 0.958\n",
      "Accuracy on training set (AT+V/PE): 0.999\n",
      "Accuracy on test set (AT+V/PE): 0.992\n",
      "Accuracy on training set (ALL/PE): 1.000\n",
      "Accuracy on test set (ALL/PE): 0.991\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=5, random_state=20)\n",
    "\n",
    "forest.fit(xt_train, yt_train)\n",
    "print(\"Accuracy on training set (AT/PE): {:.3f}\".format(forest.score(xt_train, yt_train)))\n",
    "print(\"Accuracy on test set (AT/PE): {:.3f}\".format(forest.score(xt_test, yt_test)))\n",
    "forest.fit(xv_train, yv_train)\n",
    "print(\"Accuracy on training set (V/PE): {:.3f}\".format(forest.score(xv_train, yv_train)))\n",
    "print(\"Accuracy on test set (V/PE): {:.3f}\".format(forest.score(xv_test, yv_test)))\n",
    "forest.fit(xtv_train, ytv_train)\n",
    "print(\"Accuracy on training set (AT+V/PE): {:.3f}\".format(forest.score(xtv_train, ytv_train)))\n",
    "print(\"Accuracy on test set (AT+V/PE): {:.3f}\".format(forest.score(xtv_test, ytv_test)))\n",
    "forest.fit(x_train, y_train)\n",
    "print(\"Accuracy on training set (ALL/PE): {:.3f}\".format(forest.score(x_train, y_train)))\n",
    "print(\"Accuracy on test set (ALL/PE): {:.3f}\".format(forest.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293f2adb",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "<u>For n_estimators=5: <br>\n",
    "    \n",
    "Accuracy on training set (AT/PE): 0.956<br>\n",
    "Accuracy on test set (AT/PE): 0.953<br>\n",
    "Accuracy on training set (V/PE): 0.960<br>\n",
    "Accuracy on test set (V/PE): 0.958<br>\n",
    "Accuracy on training set (AT+V/PE): 0.999<br>\n",
    "Accuracy on test set (AT+V/PE): 0.992<br>\n",
    "Accuracy on training set (ALL/PE): 1.000<br>\n",
    "Accuracy on test set (ALL/PE): 0.991<br>\n",
    "\n",
    "<u>For n_estimators=10: <br>\n",
    "    \n",
    "Accuracy on training set (AT/PE): 0.957 <br>\n",
    "Accuracy on test set (AT/PE): 0.954 <br>\n",
    "Accuracy on training set (V/PE): 0.960 <br>\n",
    "Accuracy on test set (V/PE): 0.958 <br>\n",
    "Accuracy on training set (AT+V/PE): 0.999 <br>\n",
    "Accuracy on test set (AT+V/PE): 0.992 <br>\n",
    "Accuracy on training set (ALL/PE): 1.000 <br>\n",
    "Accuracy on test set (ALL/PE): 0.991 <br>\n",
    "\n",
    "<u>For n_estimators=100: <br>\n",
    "    \n",
    "Accuracy on training set (AT/PE): 0.957 <br>\n",
    "Accuracy on test set (AT/PE): 0.954 <br>\n",
    "Accuracy on training set (V/PE): 0.960 <br>\n",
    "Accuracy on test set (V/PE): 0.958 <br>\n",
    "Accuracy on training set (AT+V/PE): 0.999 <br>\n",
    "Accuracy on test set (AT+V/PE): 0.992 <br>\n",
    "Accuracy on training set (ALL/PE): 1.000 <br>\n",
    "Accuracy on test set (ALL/PE): 0.991 <br>\n",
    "**(exactly the same as for n_estimators=10)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f2239",
   "metadata": {},
   "source": [
    "The results for the random forest predictions are exactly the same as those obtained when simple decision trees were used (for n_bins=2). The random forest ends up being a redundant extension of combining all the previous decision trees in its predictive process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d95b09",
   "metadata": {},
   "source": [
    "# Gradient boosted regression trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a4a309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set (AT/PE): 0.947\n",
      "Accuracy on test set (AT/PE): 0.951\n",
      "Accuracy on training set (V/PE): 0.949\n",
      "Accuracy on test set (V/PE): 0.949\n",
      "Accuracy on training set (AT+V/PE): 0.969\n",
      "Accuracy on test set (AT+V/PE): 0.967\n",
      "Accuracy on training set (ALL/PE): 0.977\n",
      "Accuracy on test set (ALL/PE): 0.973\n"
     ]
    }
   ],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state=21)\n",
    "\n",
    "gbrt.fit(xt_train, yt_train)\n",
    "print(\"Accuracy on training set (AT/PE): {:.3f}\".format(gbrt.score(xt_train, yt_train)))\n",
    "print(\"Accuracy on test set (AT/PE): {:.3f}\".format(gbrt.score(xt_test, yt_test)))\n",
    "gbrt.fit(xv_train, yv_train)\n",
    "print(\"Accuracy on training set (V/PE): {:.3f}\".format(gbrt.score(xv_train, yv_train)))\n",
    "print(\"Accuracy on test set (V/PE): {:.3f}\".format(gbrt.score(xv_test, yv_test)))\n",
    "gbrt.fit(xtv_train, ytv_train)\n",
    "print(\"Accuracy on training set (AT+V/PE): {:.3f}\".format(gbrt.score(xtv_train, ytv_train)))\n",
    "print(\"Accuracy on test set (AT+V/PE): {:.3f}\".format(gbrt.score(xtv_test, ytv_test)))\n",
    "gbrt.fit(x_train, y_train)\n",
    "print(\"Accuracy on training set (ALL/PE): {:.3f}\".format(gbrt.score(x_train, y_train)))\n",
    "print(\"Accuracy on test set (ALL/PE): {:.3f}\".format(gbrt.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab89821",
   "metadata": {},
   "source": [
    "Results obtained are slightly worse than those for the decision trees' and random forests' regressions."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Ã‚ngelo Ferreira"
   },
   {
    "name": "Naomi Torres"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "title": "Combined Cycle Power Plant"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
